# Configuration for the Agentic Forecasting Framework

# --- Orchestrator Configuration ---
orchestrator:
  # Enable dynamic routing via LLM (Supervisor Agent)
  # If false, uses static routing logic
  dynamic_routing_enabled: false

# --- Data Source Configuration ---
data_source:
  # Primary data source to use.
  # Options: "alpha_vantage", "ibkr"
  # If the primary source fails, the framework will attempt to use the other as a fallback.  
  primary: "alpha_vantage"# --- Training Configuration ---
training:
  # Device to use for model training.
  # Options: "auto", "cuda", "cpu"
  # "cuda" forces GPU training, will error if GPU is not available.
  # "auto" will use GPU if available, otherwise CPU
  device: "auto"

# --- Reporting Configuration ---
reporting:
  dashboard_enabled: true
  dashboard_dir: "web_dashboard"
  email_enabled: false

# --- IBKR Data Configuration ---
ibkr:
  # IB TWS/Gateway connection settings
  host: "127.0.0.1"
  port: 7497  # TWS API port (7496=paper, 7497=live)
  client_id: 1
  # Market data type to request from IBKR TWS/Gateway.
  # 1: Real-time (requires subscription)
  # 2: Frozen
  # 3: Delayed (default, no subscription required)
  # 4: Delayed frozen
  market_data_type: 3

# --- Symbols Configuration ---
# Symbols are automatically loaded from watchlist_main.csv
# No manual configuration needed - all symbols from CSV will be processed

# --- Scaling Configuration ---
scaling:
  # Maximum number of symbols to process in a single run
  max_symbols: 3  # Run for all symbols in watchlist
  # max_symbols: 1 # Run for all symbols in watchlist

  # Batch processing settings - Maximum throughput
  batch_size: 100  # Maximum symbols per batch
  batch_delay: 5   # Minimum delay between batches

  # Parallel processing - Maximum concurrency
  max_workers: 5  # Maximum concurrent workers

  # Memory management - Maximum memory allocation
  max_memory_gb: 64  # Maximum memory usage before cleanup

# --- Alpha Vantage Configuration ---
alpha_vantage:
  # API call rate limit (calls per minute) - Premium tier
  rate_limit: 150
  # Your Alpha Vantage API key (get from https://www.alphavantage.co/support/#api-key)
  api_key: "${ALPHA_VANTAGE_API_KEY}"


# --- Financial Modeling Prep (FMP) Configuration ---
fmp:
  # Your FMP API key (get from https://financialmodelingprep.com/developer/docs)
  api_key: "${FMP_API_KEY}"
  # API call rate limit (calls per minute)
  rate_limit: 300
  enabled: true
  universe: "top_liquid"

# --- CoinGecko Configuration ---
coingecko:
  # Your CoinGecko API key (optional, free tier works without key)
  # Get from https://www.coingecko.com/en/api
  api_key: "${COINGECKO_API_KEY}"
  # API call rate limit (calls per minute) - Free tier
  rate_limit: 10

# --- Frankfurter FX Configuration ---
frankfurter:
  # Frankfurter is completely free, no API key required
  # Currency data API - https://frankfurter.dev
  # Source: https://github.com/lineofflight/frankfurter
  name: "Frankfurter"
  description: "Currency data API"
  versions:
    v1: "/v1"
  docs: "https://frankfurter.dev"
  source: "https://github.com/lineofflight/frankfurter"
  api_key: ""  # No API key required - service is free
  # API call rate limit (calls per minute)
  rate_limit: 1000

# --- HPO Agent Configuration ---
hpo:
  # MAPE threshold to trigger a new HPO run. 
  # If any symbol's best model performs worse than this, HPO will be triggered.
  trigger_mape_threshold: 0.1
  
  # HPO Search Space Settings
  daily:
    small_models:
      trials: 10
      max_epochs: 10
    large_models:
      trials: 20
      max_epochs: 20
  
  weekend_hpo:
    small_models:
      trials: 30
      max_epochs: 20
    large_models:
      trials: 50
      max_epochs: 40
      
  # Early stopping patience (epochs)
  early_stopping_patience: 3

# --- Anomaly Detection Configuration ---
anomaly_detection:
  # Number of anomalies required to block a model promotion.
  anomaly_threshold: 5

# --- News Configuration ---
news:
  enabled: true
  provider: "newsapi_ai"  # "newsapi_ai" (Event Registry) or "newsapi_org"
  api_key: "${NEWSAPI_AI_KEY}"
  max_articles_per_symbol_per_day: 100
  use_in_tft: true
  use_in_graph_stgcnn: true
  
  # Shock detection thresholds
  shock_thresholds:
    sentiment_max_abs: 0.8
    article_count_spike: 10
    impact_categories: ["earnings", "guidance", "mna", "litigation", "macro"]

# --- Auto Documentation Configuration ---
auto_documentation:
  enabled: true
  report_format: "markdown"
  include_json_summary: true
  output_dir: "artifacts/reports"

# --- LangSmith Configuration ---
# To enable tracing, set the LANGCHAIN_TRACING_V2 environment variable to "true"
# and provide your API key here or as an environment variable.
langsmith:
  api_key: "${LANGCHAIN_API_KEY}" # Optional: Your LangSmith API key
  project: "agentic_forecast" # Default project name
  tracing_enabled: false  # Enable LLM tracing

# --- LLM Configuration ---
llm:
  # Which logical role uses which backend
  default_llm_roles:
    analytics_explainer:
      backend: openai_gpt4o_mini  # Primary analytics & metrics explanation
    hpo_planner:
      backend: openai_o4_mini     # HPO planning & reasoning
    news_enricher:
      backend: openai_o4_mini     # News feature extraction & structuring
    research_agent:
      backend: openai_o4_mini     # Macro research & hypothesis generation
    reporting_agent:
      backend: openai_gpt4o_mini  # Report generation (cost-effective)
    explainability_agent:
      backend: openai_gpt4o_mini  # Per-symbol explanations
    notification_agent:
      backend: openai_gpt4o_mini  # Alert processing & notifications
    strategy_planner:
      backend: openai_o4_mini     # Strategy planning & portfolio optimization

  # Concrete backends (you can add more later)
  backends:
    openai_o4_mini:
      provider: openai
      model: "o4-mini"          # Best for reasoning & planning tasks
      base_url: null            # null = default OpenAI API
    openai_gpt4o_mini:
      provider: openai
      model: "gpt-4o-mini"      # Cost-effective for analytics & explanations
      base_url: null
    openai_gpt5_mini:
      provider: openai
      model: "gpt-5-mini"       # if/when available on your account
      base_url: null

# --- Model Preferences ---
models:
  primary: ["BaselineLinear"]
  fallback: ["BaselineLinear"]
  priority_order: ["BaselineLinear"]

# --- Quality & Governance Configuration ---
quality:
  targets:
    accuracy_daily: 0.72
    rmse_rel_improve: 0.10
    hitrate_topN: 0.65
  deploy_rules:
    min_val_accuracy: 0.70
    max_rmse: 0.9
    require_human_for_trades: true
  drift:
    accuracy_window_hours: 4
    min_accuracy: 0.70
    actions:
      - type: retrain
      - type: rollback_if_val_drop_gt
        threshold: 0.05
  observability:
    tracing: langsmith
    require_trace: true
    eval_suites: ["regression_eval_v1"]
  trust_score:
    weights:
      accuracy: 0.4
      regime: 0.3
      guardrails: 0.2
      data_quality: 0.1
    thresholds:
      mape_good: 0.05
      mape_bad: 0.15
      volatility_high: 0.5
      volatility_medium: 0.3
    penalties:
      guardrail_flag: 0.2
      regime_high_vol: 0.2
      regime_medium_vol: 0.5

